# -*- coding: utf-8 -*-
"""Hotel Sentiment analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uCVj-6Afs3G1DMb3D12RsCy-YRuvDzg8
"""

import pandas as pd
import io
import nltk
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.layers import Embedding
from keras import regularizers
from keras.models import Sequential
from keras import layers
from keras import backend as bk
from keras.callbacks import ModelCheckpoint
from nltk.corpus import stopwords
from nltk.tokenize.toktok import ToktokTokenizer
from nltk.tokenize import word_tokenize,sent_tokenize

"""Uploading and viewing the dataset."""

from google.colab import files
uploaded=files.upload()

df = pd.read_csv(io.BytesIO(uploaded['tripadvisor_hotel_reviews.csv']))

print(df)

"""Find the Rating count"""

df['Rating'].value_counts()

"""Splitting the training dataset """

tr_rev=df.Review[:15000]
tr_rat=df.Rating[:15000]


#Test dataset
ts_rev=df.Review[15000:]
ts_rat=df.Rating[15000:]

print(tr_rev.shape,tr_rat.shape)
print(ts_rev.shape,ts_rat.shape)

"""Normalization"""

#Prepare data for normalization
#Tokenization
tok=ToktokTokenizer()

#Stopword list
nltk.download('stopwords')
stop_list=nltk.corpus.stopwords.words('english')

print(stop_list)

#removing stopwords
def no_stopwords(text,is_lower_case=False):
  tokens=tok.tokenize(text)
  tokens=[token.strip() for token in tokens]
  if is_lower_case:
    filt_tokens=[token for token in tokens if token not in stop_list]
  else:
    filt_tokens=[token for token in tokens if token.lower() not in stop_list]
    filt_text=' '.join(filt_tokens)
    return filt_text

    df['Review']=df['Review'].apply(no_stopwords)
    print(df['Review'])

"""Transforming sequence into array"""

ktok= Tokenizer(num_words=20941)
ktok.fit_on_texts(df['Review'])
seq=ktok.texts_to_sequences(df['Review'])
sentarr=pad_sequences(seq,20)
print(sentarr)

"""Embedding layer"""

embedding_layer=Embedding(20941,20)

"""Building the deep model using Keras"""

model1 = Sequential()
model1.add(layers.Embedding(20941,20))
model1.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))
model1.add(layers.Dense(3,activation='softmax'))
model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])
checkpoint1 = ModelCheckpoint("model", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', save_freq=1,save_weights_only=False)
#history = model1.fit(tr_rev, tr_rat, epochs=2,validation_data=(ts_rev, ts_rat),callbacks=[checkpoint1])